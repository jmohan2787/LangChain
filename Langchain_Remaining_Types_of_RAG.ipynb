{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565642dd-50dd-4a46-bc63-f03a31ee6c17",
   "metadata": {},
   "source": [
    "\n",
    "‚úÖ 4. ParentDocumentRetriever\n",
    "\n",
    "Use Case: Retrieve parent chunks based on a retrieval of smaller child chunks, great for keeping context intact in long documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500ae57d-9123-4b73-86d0-b73b6b718566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mojayara\\AppData\\Local\\Temp\\ipykernel_26440\\2395371340.py:21: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n",
      "C:\\Users\\mojayara\\AppData\\Local\\Temp\\ipykernel_26440\\2395371340.py:35: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(\"What are agents?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Retrieved Doc: Agents in LangChain use tools to answer questions.\n",
      "üìÑ Retrieved Doc: LangChain helps build LLM-powered apps with memory and agents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.schema.document import Document\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1. Load environment\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# 1. Prepare documents\n",
    "docs = [Document(page_content=\"LangChain helps build LLM-powered apps with memory and agents.\", metadata={\"id\": \"1\"}),\n",
    "        Document(page_content=\"Agents in LangChain use tools to answer questions.\", metadata={\"id\": \"2\"})]\n",
    "\n",
    "# 2. Setup child splitter\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "\n",
    "# 3. Setup vectorstore for children\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(docs, embedding)\n",
    "\n",
    "# 4. Parent retriever\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=InMemoryStore(),  # Stores parent docs\n",
    "    child_splitter=child_splitter\n",
    ")\n",
    "\n",
    "# 5. Add documents\n",
    "retriever.add_documents(docs)\n",
    "\n",
    "# 6. Retrieve\n",
    "results = retriever.get_relevant_documents(\"What are agents?\")\n",
    "for doc in results:\n",
    "    print(\"üìÑ Retrieved Doc:\", doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195b4d2-b4c9-4dbe-8f65-29947d4cefe7",
   "metadata": {},
   "source": [
    "\n",
    "‚úÖ 5. BM25Retriever\n",
    "\n",
    "Use Case: Pure keyword-based search (like traditional search engines). No embeddings needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1309f935-aed5-4274-9d5b-d5e1a187277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62c7448-1588-4945-adf4-d58ae6061887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù BM25 Result: BM25 is a classical retrieval method.\n",
      "üìù BM25 Result: Vector search is powerful.\n",
      "üìù BM25 Result: LangChain enables LLM applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "# Create simple text docs\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain enables LLM applications.\"),\n",
    "    Document(page_content=\"Vector search is powerful.\"),\n",
    "    Document(page_content=\"BM25 is a classical retrieval method.\")\n",
    "]\n",
    "\n",
    "# Create BM25 retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "\n",
    "# Retrieve\n",
    "results = bm25_retriever.get_relevant_documents(\"How does BM25 work?\")\n",
    "for doc in results:\n",
    "    print(\"üìù BM25 Result:\", doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0eab29-65be-4f6f-9eb3-90c091863f70",
   "metadata": {},
   "source": [
    "‚úÖ 6. EnsembleRetriever\n",
    "\n",
    "Use Case: Combine multiple retrievers (e.g., keyword + vector-based) with weighted scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8035e7-c13b-4ad6-a649-01809dd1fd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Ensemble Doc: You can build AI apps using LangChain.\n",
      "üîç Ensemble Doc: LangChain helps build LLM-powered apps with memory and agents.\n",
      "üîç Ensemble Doc: LangChain supports LLMs.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.vectorstores import FAISS,Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "# Sample docs\n",
    "docs = [Document(page_content=\"LangChain supports LLMs.\"), Document(page_content=\"You can build AI apps using LangChain.\")]\n",
    "\n",
    "# BM25 Retriever\n",
    "bm25 = BM25Retriever.from_documents(docs)\n",
    "\n",
    "# Vector Retriever\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(docs, embedding)\n",
    "vector_retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Ensemble Retriever (equal weight)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25, vector_retriever],\n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Query\n",
    "results = ensemble_retriever.get_relevant_documents(\"AI apps using LangChain\")\n",
    "for doc in results:\n",
    "    print(\"üîç Ensemble Doc:\", doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d968757-6f22-4688-ae97-2cbb17f1595b",
   "metadata": {},
   "source": [
    "7.TimeWeightedVectorStoreRetriever\n",
    "\n",
    "This retriever boosts document relevance by factoring recency and importance of interactions (used in agents with memory or relevance ranking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "421abfd7-2d5b-4bc4-b4ee-7a89853728e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.TimeWeightedVectorStoreRetriever\n",
    "#This retriever boosts document relevance by factoring recency and importance of interactions (used in agents with memory or relevance ranking).\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.schema import Document\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Initialize embedding & vectorstore\n",
    "embedding = OpenAIEmbeddings()\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain is for LLM-based apps\", metadata={\"last_accessed_at\": None}),\n",
    "    Document(page_content=\"Vector search improves relevance\", metadata={\"last_accessed_at\": None})\n",
    "]\n",
    "vectorstore = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "# TimeWeighted Retriever\n",
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    decay_rate=0.01,\n",
    "    k=2,\n",
    "    score_threshold=None\n",
    ")\n",
    "\n",
    "# Retrieve\n",
    "results = retriever.get_relevant_documents(\"What is LangChain?\")\n",
    "for r in results:\n",
    "    print(r)\n",
    "    print(r.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "018e2944-0f1d-472a-bea5-c7f5a087b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain.retrievers.time_weighted_vectorstore import TimeWeightedVectorStoreRetriever\n",
    "# from langchain.schema import Document\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# embedding = OpenAIEmbeddings()\n",
    "\n",
    "# # Docs with ISO timestamp strings\n",
    "# docs = [\n",
    "#     Document(\n",
    "#         page_content=\"LangChain is for LLM-based apps\",\n",
    "#         metadata={\"last_accessed_at\": (datetime.now() - timedelta(hours=1)).isoformat()}\n",
    "#     ),\n",
    "#     Document(\n",
    "#         page_content=\"Vector search improves relevance\",\n",
    "#         metadata={\"last_accessed_at\": datetime.now().isoformat()}\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# # Build FAISS vectorstore\n",
    "# vectorstore = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "# # TimeWeighted retriever\n",
    "# retriever = TimeWeightedVectorStoreRetriever(\n",
    "#     vectorstore=vectorstore,\n",
    "#     decay_rate=0.01,   # how fast old docs decay\n",
    "#     k=2\n",
    "# )\n",
    "\n",
    "# # Test query\n",
    "# results = retriever.get_relevant_documents(\"What is LangChain?\")\n",
    "\n",
    "# for r in results:\n",
    "#     print(\"CONTENT:\", r.page_content)\n",
    "#     print(\"METADATA:\", r.metadata)\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c74ce18b-357c-4433-b5cd-fdcd6e2a51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "353bf195-bd67-4134-b901-53e6deebc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e1d479b-e920-4e36-bc11-d7ee8c99484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain 1.1. LangChain v1.1.0 is now available This release makes agent development more reliable, more structured, and more context-aware ‚Äî powered by a new.\n",
      "The langchain namespace has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to langchain-classic . To upgrade\n",
      "LangChain v1.0 is now available!For a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import TavilySearchAPIRetriever\n",
    "import os\n",
    "\n",
    "# Set your Tavily API key\n",
    "#os.environ[\"TAVILY_API_KEY\"] = \"your_tavily_api_key\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# üîê Load API keys\n",
    "load_dotenv(\".env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Initialize Tavily Retriever\n",
    "retriever = TavilySearchAPIRetriever(k=3)\n",
    "\n",
    "# Perform search\n",
    "docs = retriever.get_relevant_documents(\"Latest updates about LangChain\")\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c09637-28d8-4da0-9b2a-58bfb917d922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
