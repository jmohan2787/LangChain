{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b0a87d-4a3e-4f8b-8de2-9da522de9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import Tool\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7bd2427-ebe5-4aeb-964f-f2255af95285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path='.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c39c57-438f-4b2a-82b8-a60644653b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mojayara\\AppData\\Local\\Temp\\ipykernel_38576\\2178695137.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  qa_llm=ChatOpenAI(model='gpt-3.5-turbo',temperature=0)\n"
     ]
    }
   ],
   "source": [
    "qa_llm=ChatOpenAI(model='gpt-3.5-turbo',temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c19bbf2-b024-423f-985f-e96259ccc2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mojayara\\AppData\\Local\\Temp\\ipykernel_38576\\879230737.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  qa_chain=LLMChain(llm=qa_llm,prompt=qa_prompt)\n"
     ]
    }
   ],
   "source": [
    "qa_prompt=PromptTemplate.from_template('Answer clearly: {question}')\n",
    "qa_chain=LLMChain(llm=qa_llm,prompt=qa_prompt)\n",
    "qa_tools=Tool(name=\"simple QA\",func=qa_chain.run,description=\"Answer factual question clarly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e455f5-6d63-49b5-9370-e002f88b1bb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m summerize_prompt\u001b[38;5;241m=\u001b[39mPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummerizes the input: \u001b[39m\u001b[38;5;132;01m{text}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m summerize_llm\u001b[38;5;241m=\u001b[39mLLMChain(llm\u001b[38;5;241m=\u001b[39m\u001b[43mllm\u001b[49m,prompt\u001b[38;5;241m=\u001b[39msummerize_prompt)\n\u001b[0;32m      3\u001b[0m summerize_tool\u001b[38;5;241m=\u001b[39mTool(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummarizer\u001b[39m\u001b[38;5;124m'\u001b[39m,func\u001b[38;5;241m=\u001b[39msummerize_llm\u001b[38;5;241m.\u001b[39mrun, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummerize the input text\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "summerize_prompt=PromptTemplate.from_template('summerizes the input: {text}')\n",
    "summerize_llm=LLMChain(llm=llm,prompt=summerize_prompt)\n",
    "summerize_tool=Tool(name='Summarizer',func=summerize_llm.run, description='summerize the input text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f976d3a-8879-4ec0-a9c8-65b71b056e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_query='what is langchain?'\n",
    "summary_text = \"\"\"\n",
    "LangGraph is a library built on top of LangChain that helps developers create stateful, multi-step agents \n",
    "as graphs. Each node represents a step like calling an LLM or a tool. It's ideal for advanced AI workflows.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf261409-1c12-45e0-8b2b-39bd864cae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer=qa_tools.run({'question': qa_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fadc72-69e4-485c-8e54-d7fcd57f373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9a02d-8611-41bd-9383-6c4ccd990aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "summery=summerize_tool.run({'text':summary_text })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e8c4cf-24dd-415e-ba8f-72c49d63ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "summery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c27703-5317-46a8-99cd-fee6c86df137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
