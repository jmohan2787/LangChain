{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb9401a-a975-493e-b95f-f3485e55c3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Ô∏è‚É£ First question\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: RAG_QA\n",
      "Action Input: What is LangChain?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLangChain is a framework created by Harrison Chase for building applications with LLMs. It supports RAG, agents, memory, tools, and more, and is commonly used in chatbots, document Q&A, and AI workflow.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: LangChain is a framework created by Harrison Chase for building applications with large language models. It supports various features like RAG, agents, memory, tools, and more, and is commonly used in chatbots, document Q&A, and AI workflow.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: LangChain is a framework created by Harrison Chase for building applications with large language models. It supports various features like RAG, agents, memory, tools, and more, and is commonly used in chatbots, document Q&A, and AI workflow.\n",
      "\n",
      "2Ô∏è‚É£ Follow-up\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: LangChain was created by Harrison Chase.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: LangChain was created by Harrison Chase.\n",
      "\n",
      "3Ô∏è‚É£ Ask again\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: `LangChain is a framework created by Harrison Chase for building applications with large language models. It supports features like RAG, agents, memory, tools, and more, and is commonly used in chatbots, document Q&A, and AI workflow.`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? Yes\n",
      "Action: RAG_QA\n",
      "Action Input: Explain LangChain simply\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLangChain is a framework created by Harrison Chase for building applications using Large Language Models (LLMs). It supports various features like RAG, agents, memory, tools, and more. It is commonly used in chatbots, document Q&A, and AI workflow.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: LangChain is a framework created by Harrison Chase for building applications using Large Language Models (LLMs). It supports various features like RAG, agents, memory, tools, and more. It is commonly used in chatbots, document Q&A, and AI workflow.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: LangChain is a framework created by Harrison Chase for building applications using Large Language Models (LLMs). It supports various features like RAG, agents, memory, tools, and more. It is commonly used in chatbots, document Q&A, and AI workflow.\n"
     ]
    }
   ],
   "source": [
    "#1)VectorStoreRetriever\tVector-based\tEmbedding similarity search\tGeneral-purpose RAG\n",
    "# ConversationalRetrievalChain\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# 1. Setup\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 2Ô∏è‚É£ Load API keys\n",
    "load_dotenv(\".env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 2. Vector DB\n",
    "with open(\"sample1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "# üß† Split the text into smaller chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=300, chunk_overlap=50)\n",
    "texts = splitter.split_text(text_data)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "# vectorstore = FAISS.from_texts(texts, embedding)\n",
    "vectorstore = Chroma.from_texts(texts, embedding)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 3. Conversational RAG chain\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "# 4. Memory for chat history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# 5. Wrap RAG as a StructuredTool\n",
    "def rag_tool_fn(question: str) -> str:\n",
    "    return rag_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"chat_history\": []\n",
    "    })[\"answer\"]\n",
    "\n",
    "rag_tool = StructuredTool.from_function(\n",
    "    name=\"RAG_QA\",\n",
    "    description=\"Use this to answer questions about LangChain.\",\n",
    "    func=rag_tool_fn\n",
    ")\n",
    "\n",
    "# 6. Create agent\n",
    "agent = initialize_agent(\n",
    "    tools=[rag_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# 7. Run conversation\n",
    "print(\"1Ô∏è‚É£ First question\")\n",
    "res1 = agent.run(\"What is LangChain?\")\n",
    "print(\"Answer:\", res1)\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Follow-up\")\n",
    "res2 = agent.run(\"Who created it?\")\n",
    "print(\"Answer:\", res2)\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Ask again\")\n",
    "res3 = agent.run(\"Explain LangChain again simply.\")\n",
    "print(\"Answer:\", res3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d5b7c-6f27-49d9-a493-9c3338f46ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
