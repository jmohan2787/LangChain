{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48641151-7ea6-4c68-a2c7-4639a1fc376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mojayara\\AppData\\Local\\Temp\\ipykernel_29284\\189417128.py:15: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
      "C:\\Users\\mojayara\\AppData\\Local\\Temp\\ipykernel_29284\\189417128.py:16: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Base setup complete.\n"
     ]
    }
   ],
   "source": [
    "# âœ… Step 1: Imports\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# âœ… Step 2: Load API key\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# âœ… Step 3: Setup LLM and Embeddings\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# âœ… Step 4: Load and split document\n",
    "with open(\"sample1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=300, chunk_overlap=50)\n",
    "texts = splitter.split_text(raw_text)\n",
    "documents = [Document(page_content=t) for t in texts]\n",
    "\n",
    "# âœ… Step 5: Vector Store (optional for Retriever chains)\n",
    "vectorstore = FAISS.from_texts(texts, embedding)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"âœ… Base setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ac47d9-f8a7-4009-81cd-9a01abeaa284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mojayara\\AppData\\Local\\Temp\\ipykernel_29284\\3073877003.py:14: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "C:\\Users\\mojayara\\AppData\\Local\\Temp\\ipykernel_29284\\3073877003.py:17: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain/\n",
      "  stuff_chain = StuffDocumentsChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ StuffDocumentsChain Answer: The document is about LangChain, a framework created by Harrison Chase for building applications with LLMs. It discusses the features and uses of LangChain, such as supporting RAG, agents, memory, tools, chatbots, document Q&A, and AI workflow.\n"
     ]
    }
   ],
   "source": [
    "#âœ… 4. StuffDocumentsChain\n",
    "#Use case: Combines all docs into a single string before passing to LLM (best for small number of documents).\n",
    "\n",
    "from langchain.chains import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "# Define prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Use the following context to answer the question:\\n\\n{context}\\n\\nQuestion: {question}\"\n",
    ")\n",
    "\n",
    "# Inner LLM Chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Stuff Chain\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_variable_name=\"context\"\n",
    ")\n",
    "\n",
    "# Run\n",
    "response = stuff_chain.invoke({\n",
    "    \"input_documents\": documents[:3],  # test on 3 docs\n",
    "    \"question\": \"What is this document about?\"\n",
    "})\n",
    "\n",
    "print(\"\\nðŸ“Œ StuffDocumentsChain Answer:\", response[\"output_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25963ad1-33a1-4d19-b7e3-8ff0bcd94428",
   "metadata": {},
   "source": [
    "5) Runnabale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14464108-3567-4699-aa71-d46d54bdd4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Refined Summary:\n",
      "\n",
      "LangChain is a framework developed by Harrison Chase for building applications with LLMs. It supports various features such as RAG, agents, memory, and tools, and is commonly used in chatbots, document Q&A, and AI workflow.\n"
     ]
    }
   ],
   "source": [
    "# Initial prompt to summarize the first chunk\n",
    "#Use case: Starts with a base answer and refines it using subsequent documents â€” good when each chunk contributes incrementally.\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "initial_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Write a concise summary of the following text:\n",
    "\n",
    "{context}\n",
    "\"\"\")\n",
    "\n",
    "# Refine prompt to update the previous summary with new context\n",
    "refine_prompt = PromptTemplate.from_template(\"\"\"\n",
    "We have an existing summary:\n",
    "\"{existing_answer}\"\n",
    "\n",
    "Refine the summary with this new context:\n",
    "\"{context}\"\n",
    "\n",
    "If the context isn't useful, return the original summary.\n",
    "\"\"\")\n",
    "\n",
    "# Set up individual chains\n",
    "initial_summary_chain = initial_prompt | llm | StrOutputParser()\n",
    "refine_summary_chain = refine_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Start with first chunk\n",
    "summary = initial_summary_chain.invoke({\"context\": documents[0].page_content})\n",
    "\n",
    "# Iteratively refine with remaining docs\n",
    "for doc in documents[1:]:\n",
    "    summary = refine_summary_chain.invoke({\n",
    "        \"existing_answer\": summary,\n",
    "        \"context\": doc.page_content\n",
    "    })\n",
    "\n",
    "# Output final summary\n",
    "print(\"ðŸ“„ Refined Summary:\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc3fc6-3d7c-4d37-b0d8-927f341a690e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
